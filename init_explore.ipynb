{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Recommendation Engine for Board Game Text Data\n",
    "\n",
    "This project builds off of the Recommendation Project, and the Natural Language Processing on Wikipedia comments.\n",
    "\n",
    "This is using data from boardgamegeek.com, gathered by Matt Borthwick.  The real goal here is to finish an analysis.\n",
    "This is labelled data for game, so it's a natural fit for employing the same methods as toxicity, and run with that analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Outline/Planning\n",
    "\n",
    "What is my ultimate goal here? \n",
    "- Build a recommendation engine based on reviews/scores.\n",
    "- Give score to unrated comments.\n",
    "\n",
    "My rough plan is to build up a lexicon, tokenize that data, and try to build a Naive Bayes model.  (Maybe later a Recurrent Neural network model?)\n",
    "\n",
    "Cleaning:\n",
    "* Tokenize (convert words to indices) \n",
    "* Stemming words\n",
    "* Balancing data set\n",
    "\n",
    "Embeddings:\n",
    "These are necessary to reduce the dimensionality of the problem to a scale that will fit in memory.  \n",
    "   * SVD - use SVD on the term-frequency matrix. Will use truncated SVD.  \n",
    "   * word2vec - train vectors for words based on surrounding contexts (can use pre-trained ones, like GLoVE)\n",
    "   * Keep only most common words (in both toxic/non-toxic), or highest probability of toxic/non-toxic\n",
    "\n",
    "Other Analysis possibilities:\n",
    "* Naive Bayes\n",
    "    - can find most important words\n",
    "    - simple, easy to understand baseline.\n",
    "* Support Vector Machine\n",
    "    - try ensemble method (split the data into batches, and train an SVM on each batch.  Then do a committee vote.)\n",
    "      This turns O(n_sample^3) scaling into O(n_sample^3/n_batch^2) scaling on the training.\n",
    "      This is effectively treating the kernel matrix as if it were block-diagonal, as it omits correlations between datasets.\n",
    "      Perhaps running multiple copies with different random splits would work?\n",
    "* Deep Neural Network\n",
    "    - Build a network using the term-frequency matrix as inputs.\n",
    "    - Extends the naive Bayes method.  (Might be automatic way of doing some of that SVM stuff?)\n",
    "    - Employ dropout for regularization, alongside L2 penalties.  \n",
    "     \n",
    "* Recurrent Neural Network\n",
    "    - Build up word embeddings (word2vec), or just use the pretrained ones.\n",
    "    - This one runs at the sentence/paragraph level and keeps the temporal structure.\n",
    "    - Use LSTM/GRU cells, with a couple layers. \n",
    "    - Also dropout, l2 penalties\n",
    "\n",
    "Metrics:\n",
    "    - F1 :harmonic mean of precision and recall\n",
    "    - log-loss $N^{-1}\\sum_{j=1}^N\\sum_c y_{jc}\\log \\hat{y}_{jc}$, where $j$ runs over observations, and $c$ runs over classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import log_loss,f1_score,roc_auc_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "#my code\n",
    "from bayes import cond_prob, naive_bayes\n",
    "from util import clean_up, get_subset, check_predictions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/boardgame-comments-english.csv')\n",
    "\n",
    "df_real_test=pd.read_csv('data/boardgame-comments-english-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Compiled from boardgamegeek.com by Matt Borthwick  gameID  \\\n0                                             140134  205637   \n1                                             184733    2163   \n2                                              17204   15158   \n3                                              79036   35677   \n4                                             188085  155426   \n\n                                                                                              comment   \n0  This game is the first game that totally left me satisfied after I played it.  This one hit the ...  \n1  I got into this game just as the first edition went out of print. So I was only able to buy the ...  \n2  This expansion has some edges but I like it because it forces you to change tactics when the dra...  \n3  Why bother with Le Havre if you can play Agricola? Sorry, I have to say it. The theme in Agricol...  \n4  Fun enough to discover and tinker around with. But approaching it as a game means grinding throu...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.columns=['userID','gameID','rating','comment']\n",
    "df_real_test.columns=['userID','gameID','comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   userID  gameID  rating  \\\n",
       "0  172640   24068     7.0   \n",
       "1   86674   24068     7.0   \n",
       "2   10643   24068     7.0   \n",
       "3   31171   24068     7.0   \n",
       "4  165608   24068     7.0   \n",
       "\n",
       "                                                                                               comment  \n",
       "0  Good:  Unique take on the hidden role games. The good and evil team win if they eliminate each o...  \n",
       "1  A neat social deduction game with multiple teams and winning conditions happening at the same time.  \n",
       "2  Good hidden roles werewolf style game that can accommodate a lot of players nicely. This game is...  \n",
       "3  Overall I hate Mafia/Werewolf, but this version is light, fun and fast. There was enough structu...  \n",
       "4  Fun social deduction exercise that gets merrier the more players participate. The game significa...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbabbaa828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#When are the comments made?\n",
    "plt.figure()\n",
    "df['rating'].hist(log=True,bins=101)\n",
    "plt.title('Rating Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So let's do more exploration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59789,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of unique Users\n",
    "df['userID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gameID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "userreview_counts=df.groupby('userID').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbca4d048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many reviews are there per user?\n",
    "userreview_counts.hist(log=True,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So, there are a lot of users with few reviews (again).\n",
    "\n",
    "This will come up in building a test/train split.  It depends on the task.  Are we trying to build a tool to recommend games? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#check counts of game reviews\n",
    "game_groups=df.groupby('gameID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "gamereview_counts=game_groups.apply(len)\n",
    "gamereview_mean=game_groups['rating'].apply(np.mean)\n",
    "gamereview_median=game_groups['rating'].apply(np.median)\n",
    "gamereview_05=game_groups['rating'].apply(lambda x: np.percentile(x,5))\n",
    "gamereview_95=game_groups['rating'].apply(lambda x: np.percentile(x,95))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbc4e84a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many reviews are there per game?\n",
    "plt.hist(np.log10(gamereview_counts+1),bins=50)\n",
    "plt.xlabel('Log10 number of reviews per game')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbb46e9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log10(gamereview_counts),gamereview_mean,'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_small=df.iloc[:1000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#cleaning the data\n",
    "#Can use pandas built in str functionality with regex to eliminate html tags, newlines, non-text characters. \n",
    "#Can maybe also eliminate all punctuation?  Makes any \n",
    "df['comment_clean']=clean_up(df['comment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_real_test['comment_clean']=clean_up(df_real_test['comment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Split data set into train/dev/test sets\n",
    "\n",
    "Let's grab 10% of the data for development, and 10% for training.\n",
    "Once again, we have to be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(seed=4565)\n",
    "#Split into test/training.\n",
    "Ntot=len(df)\n",
    "Ntrain=int(0.9*Ntot)\n",
    "\n",
    "msk=np.random.random(Ntot)<0.9\n",
    "df_train=df.loc[msk]\n",
    "df_test=df.loc[~msk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#take care of low ratings so minimum is 1.\n",
    "msk=df['rating']<1.0;\n",
    "df.loc[msk,'rating']=1\n",
    "\n",
    "#create binary labels for rating.\n",
    "df['pos']=(df['rating']>8.0)\n",
    "df['neg']=(df['rating']<5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So let's vectorize this sucker.\n",
    "Since this is primarily for exploration, I'm going to limit the vectorizer to fairly common words (which occur in more than 50 messages).\n",
    "Increasing this threshold seems to pull out more meaningful estimates for the conditional probabilities for positive and negative words.\n",
    "\n",
    "It's also possible to not just use  the raw count vectorizer, but also the TF-IDF, which includes an additional weighting that de-emphasizes common words.  This apparently makes a term-frequency matrix whose spectrum better matches some of the assumptions for the SVD.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#borrowing from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "count_vect=CountVectorizer(stop_words='english',lowercase=True,strip_accents='unicode',ngram_range=(1,2),min_df=20)\n",
    "X_train_counts=count_vect.fit_transform(df_train['comment_clean'])\n",
    "X_test_counts=count_vect.transform(df_test['comment_clean'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So one of the problems with going to multiple n-grams is the ease with which you start overfitting.\n",
    "Maybe I could explore adjusting this size manually, with the size of ngrams,   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vect=TfidfVectorizer(stop_words='english',lowercase=True,strip_accents='unicode',min_df=50)\n",
    "X_train_tfidf=tfidf_vect.fit_transform(df_train['comment_clean'])\n",
    "X_test_tfidf=tfidf_vect.transform(df_test['comment_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_realtest_counts=count_vect.transform(df_real_test['comment_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "if (X_train_counts.shape[0]!=df_train.shape[0]):\n",
    "   print('Lost some entries from training set!')\n",
    "if (X_test_counts.shape[0]!=df_test.shape[0]):\n",
    "   print('Lost some entries from training set!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Checking the vectorizer and finding common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I wanted to check that the vectorizer was working by outputting common words, and identifying the \"most positive/negative\" words, based on their counts.  This was useful as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#get vocabulary dictionary, then make a dataframe, with entries as rows\n",
    "#Then sort dataframe by row entry value, and then use that as the index for the counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def find_indicator_words(counts,val,count_vect):\n",
    "    voc_dict=count_vect.vocabulary_\n",
    "    voc_df=pd.DataFrame.from_dict(voc_dict,orient='index')\n",
    "    voc_df1=voc_df.sort_values(by=0)\n",
    "    #Compute conditional probabilities of toxicity for each word. \n",
    "    p_pos,pw_pos,pw_neg = cond_prob( counts, val, csmooth=0.000001)\n",
    "    #make new dataframe with conditional probabilities for words being toxic, and raw probabilities of occuring in toxic/clean messages\n",
    "    #Then sort by toxicity.\n",
    "    X_cond= pw_pos*p_pos/(pw_pos*p_pos + pw_neg*(1-p_pos))\n",
    "    word_mat=np.array([counts.sum(axis=0),X_cond,pw_neg,pw_pos]).squeeze()\n",
    "    word_df=pd.DataFrame(word_mat.T,columns=['count','pcond','p_hit','p_miss'],index=voc_df1.index)\n",
    "    word_df.sort_values('pcond',ascending=False,inplace=True)\n",
    "    print(word_df.head(n=20))\n",
    "    return word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      count     pcond         p_hit    p_miss\n",
      "rate 11                38.0  1.000000  6.504739e-14  0.000007\n",
      "user malain            29.0  1.000000  6.504739e-14  0.000006\n",
      "damaging ranking       29.0  1.000000  6.504739e-14  0.000006\n",
      "malain random          29.0  1.000000  6.504739e-14  0.000006\n",
      "ranking unknown        29.0  1.000000  6.504739e-14  0.000006\n",
      "random 1s              29.0  1.000000  6.504739e-14  0.000006\n",
      "1s bunch               29.0  1.000000  6.504739e-14  0.000006\n",
      "correcting rating      29.0  1.000000  6.504739e-14  0.000006\n",
      "malain                 29.0  1.000000  6.504739e-14  0.000006\n",
      "rating user            29.0  1.000000  6.504739e-14  0.000006\n",
      "players 2017           21.0  1.000000  6.504739e-14  0.000004\n",
      "simply greatest        21.0  1.000000  6.504739e-14  0.000004\n",
      "simply favorite        20.0  1.000000  6.504739e-14  0.000004\n",
      "unknown games          31.0  0.965064  6.504745e-08  0.000006\n",
      "really damaging        30.0  0.963903  6.504745e-08  0.000006\n",
      "jlnelson73 wordpress   23.0  0.952957  6.504745e-08  0.000004\n",
      "jlnelson73             23.0  0.952957  6.504745e-08  0.000004\n",
      "greatest board         36.0  0.939952  1.300948e-07  0.000007\n",
      "simply perfect         30.0  0.928011  1.300948e-07  0.000005\n",
      "wait season            44.0  0.926384  1.951422e-07  0.000008\n"
     ]
    }
   ],
   "source": [
    "posword_df=find_indicator_words(X_train_counts,df_train['pos'].values,count_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Some of these positive words aren't very helpful.  For example \"boardgameexpansion\" seems to come from urls.\n",
    "\"eldadodejack\" is some guys website.  Otherwise, these are also the names of the games!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         count     pcond         p_hit    p_miss\n",
      "smjj                      82.0  1.000000  5.273352e-14  0.000051\n",
      "smjj loves                53.0  1.000000  5.273352e-14  0.000033\n",
      "inanimate unintelligent   29.0  1.000000  5.273352e-14  0.000018\n",
      "unsatisfied id            28.0  1.000000  5.273352e-14  0.000017\n",
      "algorithm left            28.0  1.000000  5.273352e-14  0.000017\n",
      "random inanimate          28.0  1.000000  5.273352e-14  0.000017\n",
      "unintelligent algorithm   28.0  1.000000  5.273352e-14  0.000017\n",
      "thanks smjj               26.0  1.000000  5.273352e-14  0.000016\n",
      "puzzles win               30.0  0.964691  5.273357e-08  0.000018\n",
      "inanimate                 34.0  0.937787  1.054671e-07  0.000020\n",
      "unintelligent             33.0  0.904041  1.582006e-07  0.000019\n",
      "basis waste               21.0  0.899498  1.054671e-07  0.000012\n",
      "versus team               65.0  0.854271  4.746017e-07  0.000035\n",
      "luck boring               21.0  0.849685  1.582006e-07  0.000011\n",
      "boring boring            154.0  0.829389  1.318338e-06  0.000081\n",
      "excuse game               24.0  0.824886  2.109341e-07  0.000012\n",
      "feeling unsatisfied       35.0  0.819935  3.164012e-07  0.000018\n",
      "piece crap                52.0  0.818222  4.746017e-07  0.000027\n",
      "2016 reduced              33.0  0.809142  3.164012e-07  0.000017\n",
      "talked occasion           20.0  0.790288  2.109341e-07  0.000010\n"
     ]
    }
   ],
   "source": [
    "negword_df=find_indicator_words(X_train_counts,df_train['neg'].values,count_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So let's look at what this pulled out for \"negative words\".\n",
    "\n",
    "There are expressions of boredom: \"interminable, torture, numbingly\".\n",
    "Disgust: \"yuck, blech, garbage,ugh\"\n",
    "Dislike:\"torture, garbage, hatred, loathe\"\n",
    "\n",
    "One of these might be a user's name: smjj. Perhaps from a genius who protests giving scores at all and gives everything 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def find_words(df,st):\n",
    "    msk=df['comment_clean'].str.contains(st)\n",
    "    print(df[msk].head())\n",
    "    print(df[msk].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userID  gameID  rating  \\\n",
      "12684   86991   10630     9.0   \n",
      "12761   86991  105551     9.0   \n",
      "26337   86991    1927     8.0   \n",
      "40390   86991  157354     9.0   \n",
      "62266   86991  150376    10.0   \n",
      "\n",
      "                                                                                                   comment  \\\n",
      "12684  Wonderfully elegant and light wargame. Simple enough to make it accessible to everyone while lea...   \n",
      "12761  It's got some very good heavy euro mechanisms tied to a strong theme and with a great deal of ne...   \n",
      "26337  Fun if played for laughs with the right group of people. If you try to play it \"seriously\" or de...   \n",
      "40390  The best Feld game I've ever played was not designed by Feld. Shocking.  Spanish review: http://...   \n",
      "62266  A game that redefines hidden roles, focusing more on personal conflict and storytelling than on ...   \n",
      "\n",
      "         pos    neg  \\\n",
      "12684   True  False   \n",
      "12761   True  False   \n",
      "26337  False  False   \n",
      "40390   True  False   \n",
      "62266   True  False   \n",
      "\n",
      "                                                                                             comment_clean  \n",
      "12684  wonderfully elegant and light wargame simple enough to make it accessible to everyone while leav...  \n",
      "12761  its got some very good heavy euro mechanisms tied to a strong theme and with a great deal of neg...  \n",
      "26337  fun if played for laughs with the right group of people if you try to play it seriously or devel...  \n",
      "40390  the best feld game ive ever played was not designed by feld shocking spanish review http eldadod...  \n",
      "62266  a game that redefines hidden roles focusing more on personal conflict and storytelling than on p...  \n",
      "        userID  gameID  rating  \\\n",
      "690334   86991  160499     8.0   \n",
      "693870   86991   28023     8.0   \n",
      "770847   86991  129622     8.0   \n",
      "786709   86991     118     8.0   \n",
      "794322   86991    1406     5.0   \n",
      "\n",
      "                                                                                                    comment  \\\n",
      "690334  Solves some of the problems with King of Tokyo, although making it slightly more complex.  Spani...   \n",
      "693870  Family racing game with pirate theme and lots of opportunities to mess with other players.  Span...   \n",
      "770847  The most famous and, in my opinion, still best microgame.  Spanish review: http://eldadodejack.w...   \n",
      "786709  A great pure auction game, which focuses on auctioning (no distracting elements). The different ...   \n",
      "794322  Too long for a luck-driven game. The negotiation part was kind of fun, but now there are far mor...   \n",
      "\n",
      "          pos    neg  \\\n",
      "690334  False  False   \n",
      "693870  False  False   \n",
      "770847  False  False   \n",
      "786709  False  False   \n",
      "794322  False  False   \n",
      "\n",
      "                                                                                              comment_clean  \n",
      "690334  solves some of the problems with king of tokyo although making it slightly more complex spanish ...  \n",
      "693870  family racing game with pirate theme and lots of opportunities to mess with other players spanis...  \n",
      "770847  the most famous and in my opinion still best microgame spanish review http eldadodejack wordpres...  \n",
      "786709  a great pure auction game which focuses on auctioning no distracting elements the different bidd...  \n",
      "794322  too long for a luck driven game the negotiation part was kind of fun but now there are far more ...  \n"
     ]
    }
   ],
   "source": [
    "find_words(df_train,'eldadodejack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So, we've evidently found someone who rates all games 1, or 10, and their enemies squabbling.\n",
    "Eliminating some duplicates will help with this for the text rating purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Look like there is also some markup garbage in there as well from fancier reviews, or people linking to google docs where they might have their own ratings.  Some leftover html as well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# K-folds\n",
    "\n",
    "Let's split the training data into k-folds so we can do some cross-validation for tuning hyper-parameters.\n",
    "This will primarily show up on tuning the vectorization procedure, and any fitting hyper parameters (regularization).\n",
    "For Naive Bayes, there aren't any parameters, but this will be useful for the neural networks, and setting the penalty.\n",
    "I'll "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "skf=StratifiedKFold(n_splits=5,random_state=20483)\n",
    "#grab the first iteration here.\n",
    "train_index, dev_index=skf.split(df_train, df_train['pos']).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_train0=df_train.iloc[train_index]\n",
    "df_dev0=df_train.iloc[dev_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "I want to implement a Naive Bayes classifier as a baseline.  I've written my own version, which I will try to compare to\n",
    "scikit-learn's version.  (They both return the same result now).\n",
    "\n",
    "This basically treats the comments in a bag-of-words sense, and drops any correlations between the words.  \n",
    "\n",
    "* Estimate $p(w|T)$ from counts in term-frequency matrix.\n",
    "* Use Bayes Rule\n",
    "  $ P(T|w) = \\frac{p(T)p(w|T)}{\\text{normalization const}}$\n",
    "\n",
    "  \\begin{equation}\n",
    "    p(T|\\text{words}) = P(T) \\prod_{words}\\frac{p(w_i|T)}{p(w_i|T)\n",
    "  \\end{equation}\n",
    "\n",
    "* Use Logarithms, and compare log-odds for toxicity/non-toxic.\n",
    "\n",
    "So this is a classification point of view.  Ultimately, we want to treat this as a regression problem.\n",
    "A classification algorithm is a poor fit for this, since it ignores the similarity between adjacent scores. \n",
    "Nonetheless, I have a working version, so let's play with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/Data-Science/PDSG_DataScience/PDSG_rectext/bayes.py:57: RuntimeWarning: overflow encountered in exp\n",
      "  prob=1/(1+np.exp(log_Cscore-log_Tscore))\n"
     ]
    }
   ],
   "source": [
    "#go though this split, and find the hits\n",
    "actual=df_train0['pos'].values\n",
    "actual_dev=df_dev0['pos'].values\n",
    "msk=actual\n",
    "#find indices for both split and hit.\n",
    "train_hit_msk=train_index[msk]\n",
    "Xhit = X_train_counts[train_index]\n",
    "#compute conditional probabilities within this sample\n",
    "p_hit,pw_hit,pw_miss = cond_prob( Xhit, actual, csmooth=0.000001)\n",
    "#now compute the bayes factors\n",
    "pred,prob,logH,logM,log_Hword,log_Mword=naive_bayes(Xhit,pw_hit,pw_miss,p_hit)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbb50c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Plot a histogram of the log probabilities.  \n",
    "plt.figure()\n",
    "plt.hist(np.maximum(-10,np.log(prob)),bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbb62b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot a histogram of the log-odds \n",
    "plt.figure()\n",
    "bins=np.linspace(-50,50,100)\n",
    "plt.hist(logH-logM,bins=bins,log=True)\n",
    "plt.ylabel('Counts')\n",
    "plt.xlabel('Log Odds of Hit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Maybe should also plot length of comments? To what extent are these mirroring a similar underlying shape, with long tails?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbb663898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "com_len=df_train['comment_clean'].apply(lambda x: len(str.split(x,' ')))\n",
    "plt.hist(np.log10(com_len),log=True)\n",
    "plt.xlabel('Log-Character length of message')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss is 7.2079829918574685\n",
      "AUROC is 0.7282859065985177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(606412, 1) (606412, 1)\n",
      "True Positive 0.1442995851005587. False Positive 0.1158041067788896\n",
      "False Negative 0.092885694874112. True Negative 0.6470106132464397\n"
     ]
    }
   ],
   "source": [
    "logloss,score_rates=check_predictions(pred,actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Interesting. The mean log-loss is surprisingly sensitive to the chosen zero-offset.  I think this reflects the fact that the naive-bayes method is returning a lot of incredibly small probabilities (10^{-100})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB(alpha=0.01)\n",
    "nb.fit(X_train_counts[train_index],df_train0['pos'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Make predictions on training/dev sets\n",
    "pred_nb=nb.predict(X_train_counts[train_index])\n",
    "pred_dev_nb=nb.predict(X_train_counts[dev_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss is 7.216298741049285\n",
      "AUROC is 0.7281041422199969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Training data\n",
      "(606412, 1) (606412, 1)\n",
      "True Positive 0.14428309466171513. False Positive 0.116028376747162\n",
      "False Negative 0.09290218531295555. True Negative 0.6467863432781673\n"
     ]
    }
   ],
   "source": [
    "print('Checking Training data')\n",
    "nb_stats=check_predictions(pred_nb,actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "One of the errors I've found comes from when the vectorizer transforms a sentence with no recognized words.  Those sentences are lost.  The sparse algorithm ditches those rows? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dev set\n",
      "(151604, 1) (151604, 1)\n",
      "True Positive 0.13168517981055908. False Positive 0.12603229466240995\n",
      "False Negative 0.10549853565868975. True Negative 0.6367839898683412\n",
      "Log-loss is 7.996892352087403\n",
      "AUROC is 0.6949917852372789\n"
     ]
    }
   ],
   "source": [
    "print('Checking dev set')\n",
    "nb_stats=check_predictions(pred_dev_nb,actual_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So how is that doing?  What fraction have reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43027677552555027"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Naive Bayes False Positives and Negatives\n",
    "\n",
    "Let's now look a bit at the misclassified results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#fixing shapes to avoid broadcasting\n",
    "actual=np.reshape(actual,(len(actual),1))\n",
    "pred=np.reshape(pred,(len(actual),1))    \n",
    "\n",
    "fp_msk = ((pred==True)&(actual==False))    \n",
    "fn_msk = ((pred==False)&(actual==True))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_fn=df_train0[fn_msk][['comment','rating']]\n",
    "df_fp=df_train0[fp_msk][['comment','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                    comment  \\\n168250                                                      + Pandemic: In the Lab + Pandemic: On the Brink   \n168253  First game design that blew my mind. Instant classic for me and everyone I show it to. I should ...   \n168278  Clearly deserving of all the plaudits (and I don't care much for the BIG DEBATE)  An outstanding...   \n168282  First game of Age of Steam. Great game, great tension, and there are obviously some mistakes tha...   \n168290  It's been a long time since i've had such a good impression about a game. It is a game of managi...   \n\n        rating  \n168250     7.0  \n168253     7.0  \n168278     6.0  \n168282     6.0  \n168290     6.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                    comment  \\\n",
       "167395                  I really enjoyed it but i have only played it once and i would like to play again!    \n",
       "167405  Not a big fan of deckbuilders, nor do I typically like one one one destruction confrontation, bu...   \n",
       "167406  1000 games @ 57% win rate on the app. Unsure if that is a good result or just perserverance. upd...   \n",
       "167408  I like this deckbuilding game a lot, and I've played it a ton digitally. It's small enough to ea...   \n",
       "167412                                                                                         Now on iPad.   \n",
       "\n",
       "        rating  \n",
       "167395     9.5  \n",
       "167405     8.0  \n",
       "167406     8.0  \n",
       "167408     8.0  \n",
       "167412     8.0  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## Multiple Classes\n",
    "\n",
    "For fun, let's try putting each review into a bucket based on the score, and build a Naive Bayes classifier for each bin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Ytrain=np.floor(df_train['rating']*2).values.astype(int)\n",
    "Ytrain0=Ytrain[train_index]\n",
    "Ydev0=Ytrain[dev_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_all = MultinomialNB(alpha=0.01)\n",
    "nb_all.fit(X_train_counts[train_index],Ytrain0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pred_nb_all=nb_all.predict(X_train_counts[train_index])/2\n",
    "pred_dev_nb_all=nb_all.predict(X_train_counts[dev_index])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def errors(x,y):\n",
    "    rmse=np.sqrt(np.mean( (x-y)*(x-y)))\n",
    "    mad=np.mean(np.abs(x-y))\n",
    "    return rmse,mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4519374478682496, 0.9042549691133924)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(pred_nb_all,df_train0['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6923247664589591, 1.2955374099289365)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(7.2,df_train0['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's check this against the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.6482452581473976, 1.1801908611250402)\n",
      "(7.121455623653504, 6.943727082860698)\n"
     ]
    }
   ],
   "source": [
    "print(errors(pred_dev_nb_all,df_dev0['rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7017978234173143, 1.3059945541675015)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(7.2,df_dev0['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "So, it does a bit better than the super simple guess.\n",
    "One of the downsides of this particular problem is that the scores are fairly similar.\n",
    "These are by and large, good games, so they have good scores. \n",
    "People also use the rating scale inconsistently, so there is quite a bit of noise.\n",
    "\n",
    "I think this (like the previous rating experiment) will struggle to push below this noise floor.\n",
    "Nor is it really important?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2016890870378365"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#now predict all counts\n",
    "pred_realtest_nb=nb_all.predict(X_realtest_counts)/2\n",
    "df_real_test['nb']=pred_realtest_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_real_test['const']=7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_real_test[['userID','gameID','nb']].to_csv('data/nb_test_pred.csv',index=False)\n",
    "df_real_test[['userID','gameID','const']].to_csv('data/const_test_pred.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "We could just face the fact this is a regression problem, and build a linear regressor on the term-frequency matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ridge=linear_model.Ridge(alpha=0.01)\n",
    "lasso=linear_model.Lasso(alpha=0.01)\n",
    "Y=df_train['rating'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Lasso\n",
    "\n",
    "Let's try using the lasso. Currently, it seems to just fit the mean.\n",
    "The lasso is a regularized linear regression, which tends to return sparse models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7. ,  7. ,  7. , ...,  7.5,  7.5,  7.5])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000,\n   normalize=False, positive=False, precompute=False, random_state=None,\n   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(X_train_counts[train_index], Y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5968342564669999, 1.2082255947862153)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lpred=lasso.predict(X_train_counts[train_index])\n",
    "Lpred_dev=lasso.predict(X_train_counts[dev_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Lpred_real_test=lasso.predict(X_realtest_counts)\n",
    "df_real_test['Lpred']=Lpred_real_test\n",
    "df_real_test[['userID','gameID','Lpred']].to_csv('data/lasso_test_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso train error: (1.5968342564669999, 1.2082255947862153)\n",
      "Lasso dev error: (1.603519303584094, 1.2167404918314322)\n"
     ]
    }
   ],
   "source": [
    "print('Lasso train error:',errors(Lpred,Y[train_index]))\n",
    "print('Lasso dev error:',errors(Lpred_dev,Y[dev_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb8d6c6a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(131)\n",
    "plt.hist(Lpred,bins=np.arange(1,11),log=True)\n",
    "plt.title('Lasso Regression')\n",
    "plt.subplot(132)\n",
    "plt.hist(pred_nb_all,bins=np.arange(1,11),log=True)\n",
    "plt.title('Naive Bayes Multiclassification')\n",
    "plt.subplot(133)\n",
    "plt.hist(df['rating'],bins=np.arange(1,11),log=True)\n",
    "plt.title('Actual Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41411842009948163"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lpred.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "Let's use the truncated SVD for dimensionality reduction (or latent semantic analysis?)\n",
    "Apparently TF-IDF matrix is superior to straight term frequency matrix for this purpose  (more closely matches assumptions in the SVD about the noise.)\n",
    "Should maybe also symmetrize transformation (as suggested in paper comparing hyperparameters between word2vec and older SVD methods).\n",
    "They suggest using $T=U \\Lambda V = (U \\Lambda^{1/2}) (\\Lambda^{1/2} V)$ for the projection.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=100, n_iter=20,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "#took a minute or two\n",
    "TSVD=TruncatedSVD(n_components=100,n_iter=20)\n",
    "TSVD.fit(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#actually transform the results \n",
    "X_train_trans=TSVD.transform(X_train_tfidf)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb7b189e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEOCAYAAABW2BpyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEnUKHxERiTqFj4iIRJ3CR0REou7/AISo7dIoPgaVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb6afbef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog(TSVD.explained_variance_)\n",
    "plt.xlabel('Singular value label')\n",
    "plt.ylabel('Singular value')\n",
    "plt.show()\n",
    "plt.plot(TSVD.explained_variance_)\n",
    "plt.xlabel('Singular value label')\n",
    "plt.ylabel('Singular value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So looks like power-law decay in the spectrum. We're primarily interested in using this\n",
    "for dimensionality reduction.  Ideally, I'd pick some reasonable threshold for keeping a\n",
    "certain fraction of the explained variance.\n",
    "(Could estimate a power law tail, compute threshold to capture that percentage).\n",
    "\n",
    "But for now, we'll just set the threshold to be 100, as a suitably small arbitrary choice.  \n",
    "We will next use the transformed results in a \"deep\" neural network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#actually transform the dev/test data.\n",
    "X_dev_trans=TSVD.transform(X_dev_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Nsub=1000\n",
    "np.random.seed(454)\n",
    "#Should really update to just use sklearn's stratified Kfold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Deep Network\n",
    "\n",
    "Another idea is to build a deep neural network on the term-frequency matrix, effectively running with extensions to the Naive Bayes model.\n",
    "This will use the reduced term-frequency matrix after the Truncated SVD.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected, l2_regularizer\n",
    "from tensorflow.contrib.rnn import BasicRNNCell,LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from deep_network import deep_dropout_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb80f7dd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #1000. Current log-loss:0.13786394894123077\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Error encountered when serializing regularization_losses.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'function' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "#Ignore the \"error about serializing - this is a known problem with saving models created using \n",
    "#modules like fully connected, since their components are not named.\n",
    "#The models are saved, and the computations work.\n",
    "\n",
    "actual=df_train['toxic'].astype(int).values\n",
    "save_name='./tf_models/deep_relu_drop'\n",
    "dNN=deep_dropout_NN(X_train_trans.shape)\n",
    "dNN.run_graph(X_train_trans,actual,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newer predict\n",
      "INFO:tensorflow:Restoring parameters from ./tf_models/deep_relu_drop-1000\n"
     ]
    }
   ],
   "source": [
    "#model_name='tf_models/deep_relu_drop-{}'.format(dNN.n_iter)\n",
    "model_name='./tf_models/deep_relu_drop-{}'.format(1000)\n",
    "dnn_pred2=dNN.predict_all(model_name,X_train_trans)\n",
    "dnn_pred2=dnn_pred2.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive 0.06058354438328066. False Positive 0.006645457019067752\n",
      "False Negative 0.036105238922494086. True Negative 0.8966657596751575\n",
      "Log-loss is 1.4765620415427758\n",
      "AUROC is 0.8096130944597727\n"
     ]
    }
   ],
   "source": [
    "#Check scores on training data\n",
    "dnn_conf=check_predictions(dnn_pred2,actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive 0.08531301672352806. False Positive 0.01651422232454947\n",
      "False Negative 0.011375766582246687. True Negative 0.8867969943696757\n",
      "Log-loss is 0.9632992952381051\n",
      "AUROC is 0.9320323498876192\n"
     ]
    }
   ],
   "source": [
    "#Compare with naive-bayes training\n",
    "nb_conf=check_predictions(pred_nb,actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Right now the network seems undertrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## Predictions from Deep Neural Network\n",
    "\n",
    "Let's now run some predictions on the full training and development sets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newer predict\n",
      "INFO:tensorflow:Restoring parameters from tf_models/deep_relu_drop-1000\n",
      "4 layer ReLU network: on Dev set\n",
      "True Positive 0.06067773196307847. False Positive 0.006614061159135149\n",
      "False Negative 0.036011051342696276. True Negative 0.8966971555350901\n",
      "Log-loss is 1.4722245180949745\n",
      "AUROC is 0.8101175383672511\n",
      "newer predict\n",
      "INFO:tensorflow:Restoring parameters from tf_models/deep_relu_drop-1000\n",
      "4 layer ReLU network: on Dev set\n",
      "True Positive 0.05386029984727114. False Positive 0.011594925661565315\n",
      "False Negative 0.04173549855063429. True Negative 0.8928092759405293\n",
      "Log-loss is 1.841976868183656\n",
      "AUROC is 0.7752982535343149\n"
     ]
    }
   ],
   "source": [
    "#Try testing on the dev-set\n",
    "model_name='tf_models/deep_relu_drop-{}'.format(dNN.n_iter)\n",
    "nn_pred_train = dNN.predict_all(model_name,X_train_trans)\n",
    "print('4 layer ReLU network: on Dev set')\n",
    "actual_train=df_train['toxic'].values\n",
    "nn_pred_train=nn_pred_train.reshape(-1)\n",
    "nn_stats=check_predictions(nn_pred_train,actual_train)\n",
    "\n",
    "nn_pred_dev = dNN.predict_all(model_name,X_dev_trans)\n",
    "print('4 layer ReLU network: on Dev set')\n",
    "actual_dev=df_dev['toxic'].values\n",
    "nn_pred_dev=nn_pred_dev.reshape(-1)\n",
    "nn_stats=check_predictions(nn_pred_dev,actual_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes on Dev set\n",
      "True Positive 0.06311753888352087. False Positive 0.02322102047813484\n",
      "False Negative 0.032478259514384565. True Negative 0.8811831811239598\n",
      "Log-loss is 1.9238035444874515\n",
      "AUROC is 0.8172894153987111\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes on Dev set')\n",
    "pred_dev_nb=nb.predict(X_dev_counts)\n",
    "nb_stats=check_predictions(pred_dev_nb,actual_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Prior work with a (3-layer ReLU-tanh) network led to over-fitting to the training set.  Not surprising, since there was no regularization here.\n",
    "It could outperform the Naive Bayes method on the training set, but had worse performance on the development dataset.\n",
    "\n",
    "Let's put in some dropout. Putting in dropout after each layer, with a 0.1 dropout probability improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.63848495096381463, 0.69363963655066008]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dev scores\n",
    "[f1_score(actual_dev,nn_pred_dev),f1_score(actual_dev,pred_dev_nb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75269211943220748, 0.97498410006359981]\n",
      "[0.68780126065999259, 0.66262049268118539]\n"
     ]
    }
   ],
   "source": [
    "print([f1_score(actual,nn_pred_train),f1_score(actual,pred_nb)])\n",
    "print([f1_score(actual_dev,nn_pred_dev),f1_score(actual_dev,pred_dev_nb)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I am finding that beyond one or two layers, the network just seems to output zeros.  Maybe the learning rate was too high? Yes - this is a common problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "So let's try the current flavour of the month approach: a recurrent neural network.\n",
    "Based on talking to Joseph and Fahim at the group, they used a two-layer neural network based on the just the 2000 most common words, using ReLU activation.  (I think they said their approach was inspired by someone at Kaggle.)\n",
    "Let's try something similar, with initially a single layer leaky ReLU layer.\n",
    "\n",
    "The idea is that the network parses each word of the sentence (to better capture logical structure).\n",
    "Each word needs an index.  Initially this is an index in the vocabulary V, where $V\\sim10^6$ or more.  That's an infeasibly large matrix.\n",
    "We need some form of dimensionality reduction.  Either by picking the most distinctive words (which actually appear in multiple messages),\n",
    "or by projecting down via SVD. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "init_explore.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
