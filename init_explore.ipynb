{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Recommendation Engine for Board Game Text Data\n",
    "\n",
    "This project builds off of the Recommendation Project, and the Natural Language Processing on Wikipedia comments.\n",
    "\n",
    "This project uses data from boardgamegeek.com, gathered by Matt Borthwick (dive-into.info).\n",
    "The data are around 600k comments on boardgame ratings for around 400 games.  I think these are the 400 most reviewed games on the site. \n",
    "Each rating has a score from 1-10, so we can do some sentiment analysis on this.\n",
    "\n",
    "So a couple possible tasks arise: can you predict the score from a games text?\n",
    "Can you recommend other possible games based on the text?\n",
    "Related: does a game mention other games in a positive light?\n",
    "\n",
    "(The real goal here is to finish an analysis, with a slightly more friendly data set, than idiots screaming racism, misogyny and homophobia.)\n",
    "This is labelled data for game, so it's a natural fit for employing the same methods as toxicity, and run with that analysis.\n",
    "\n",
    "In this case, however, our desired output is a numerical score.  As we'll see, this leads to some issues as the scores are skewed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Outline/Planning\n",
    "\n",
    "What is my ultimate goal here? \n",
    "- Build a recommendation engine based on reviews/scores.\n",
    "- Give score to unrated comments.\n",
    "\n",
    "My rough plan is to build up a lexicon, tokenize that data, and try to build a Naive Bayes model.  (Maybe later a Recurrent Neural network model?)\n",
    "\n",
    "Cleaning:\n",
    "* Tokenize (convert words to indices) \n",
    "* Stemming words\n",
    "* Balancing data set\n",
    "\n",
    "Embeddings:\n",
    "These are necessary to reduce the dimensionality of the problem to a scale that will fit in memory.\n",
    "   * SVD - use SVD on the term-frequency matrix. Will use truncated SVD.\n",
    "   * word2vec - train vectors for words based on surrounding contexts (can use pre-trained ones, like GLoVE)\n",
    "   * Keep only most common words (in both toxic/non-toxic), or highest probability of toxic/non-toxic\n",
    "\n",
    "Other Analysis possibilities:\n",
    "* Naive Bayes\n",
    "    - can find most important words\n",
    "    - simple, easy to understand baseline.\n",
    "    \n",
    "* Support Vector Machine\n",
    "    - try ensemble method (split the data into batches, and train an SVM on each batch.  Then do a committee vote.)\n",
    "      This turns O(n_sample^3) scaling into O(n_sample^3/n_batch^2) scaling on the training.\n",
    "      This is effectively treating the kernel matrix as if it were block-diagonal, as it omits correlations between datasets.\n",
    "      Perhaps running multiple copies with different random splits would work?\n",
    "\n",
    "* Linear Regression\n",
    "   - use regularized linear regression to predict scores based on word counts.\n",
    "   - lasso and Ridge regression\n",
    "      \n",
    "* Deep Neural Network\n",
    "    - Build a network using the term-frequency matrix as inputs.\n",
    "    - Extends the naive Bayes method.  (Might be automatic way of doing some of that SVM stuff?)\n",
    "    - Employ dropout for regularization, alongside L2 penalties.  \n",
    "     \n",
    "* Recurrent Neural Network\n",
    "    - Build up word embeddings (word2vec), or just use the pretrained ones.\n",
    "    - This one runs at the sentence/paragraph level and keeps the temporal structure.\n",
    "    - Use LSTM/GRU cells, with a couple layers. \n",
    "    - Also dropout, l2 penalties\n",
    "\n",
    "Metrics:\n",
    "    - F1 :harmonic mean of precision and recall\n",
    "    - log-loss $N^{-1}\\sum_{j=1}^N\\sum_c y_{jc}\\log \\hat{y}_{jc}$, where $j$ runs over observations, and $c$ runs over classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import log_loss,f1_score,roc_auc_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#my code\n",
    "from bayes import cond_prob, naive_bayes\n",
    "from util import clean_up, get_subset, check_predictions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/boardgame-comments-english.csv')\n",
    "df_real_test=pd.read_csv('data/boardgame-comments-english-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Change Columns.\n",
    "df.columns=['userID','gameID','rating','comment']\n",
    "df_real_test.columns=['userID','gameID','comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   userID  gameID  rating  \\\n",
       "0  172640   24068     7.0   \n",
       "1   86674   24068     7.0   \n",
       "2   10643   24068     7.0   \n",
       "3   31171   24068     7.0   \n",
       "4  165608   24068     7.0   \n",
       "\n",
       "                                                                                               comment  \n",
       "0  Good:  Unique take on the hidden role games. The good and evil team win if they eliminate each o...  \n",
       "1  A neat social deduction game with multiple teams and winning conditions happening at the same time.  \n",
       "2  Good hidden roles werewolf style game that can accommodate a lot of players nicely. This game is...  \n",
       "3  Overall I hate Mafia/Werewolf, but this version is light, fun and fast. There was enough structu...  \n",
       "4  Fun social deduction exercise that gets merrier the more players participate. The game significa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb0a37710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#When are the comments made?\n",
    "plt.figure()\n",
    "df['rating'].hist(log=True,bins=101)\n",
    "plt.title('Rating Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So let's do more exploration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59789,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of unique Users\n",
    "df['userID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gameID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "userreview_counts=df.groupby('userID').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbb4c81d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many reviews are there per user?\n",
    "userreview_counts.hist(log=True,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So, there are a lot of users with few reviews (again).\n",
    "\n",
    "This will come up in building a test/train split.  It depends on the task.  Are we trying to build a tool to recommend games? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#check counts of game reviews\n",
    "game_groups=df.groupby('gameID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "gamereview_counts=game_groups.apply(len)\n",
    "gamereview_mean=game_groups['rating'].apply(np.mean)\n",
    "gamereview_median=game_groups['rating'].apply(np.median)\n",
    "gamereview_05=game_groups['rating'].apply(lambda x: np.percentile(x,5))\n",
    "gamereview_95=game_groups['rating'].apply(lambda x: np.percentile(x,95))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbb3ac9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many reviews are there per game?\n",
    "plt.hist(np.log10(gamereview_counts+1),bins=50)\n",
    "plt.xlabel('Log10 number of reviews per game')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbd2a32b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Any correlation between review number and average score?  Not really.\n",
    "plt.plot(np.log10(gamereview_counts),gamereview_mean,'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#So how many comments are duplicated? \n",
    "dup_msk=df.duplicated(subset=['userID','comment'])\n",
    "df_dup=df.loc[dup_msk]\n",
    "# (dup_msk.sum(),len(dup_msk))\n",
    "# Let's isolate those comments, and treat them separately.\n",
    "# There's around 15k of these, so less than 1%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        userID  gameID  rating          comment\n841449    2304   31260     9.0      Plays solo.\n841450    9807   31260     9.0       Chris owns\n841451  150460   31260     9.0           Played\n841537  170353   35677     9.5        One game.\n841637   53402   70323     7.5  Play with Linus"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['userID','comment'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So only around 1\\% of these comments are duplicated across multiple games.  I'm going to toss these out.\n",
    "It doesn't make a huge difference, but I doubt there is much value in most of these reviews.  In addition, it fouls up my attempts to estimate positive/negative words.\n",
    "\n",
    "Next I'll \"clean\" the comments up.  This is meant to strip out numerical, non-text characters, and markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#cleaning the data\n",
    "#Can use pandas built in str functionality with regex to eliminate html tags, newlines, non-text characters. \n",
    "#Can maybe also eliminate all punctuation?  Makes any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df['comment_clean']=clean_up(df['comment'])\n",
    "df_real_test['comment_clean']=clean_up(df_real_test['comment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Split data set into train/dev/test sets\n",
    "\n",
    "At the outset, let's grab 10% of the data for testing, and use the remaining 90% for training.\n",
    "We'll do parameter selection via k-fold cross validation, with k=5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#take care of low ratings so minimum is 1. (there are a couple tiny ratings)\n",
    "msk=df['rating']<1.0;\n",
    "df.loc[msk,'rating']=1\n",
    "\n",
    "#create binary labels for rating.\n",
    "#This is useful for directly porting over binary classification code, and detecting sentiment.  \n",
    "df['pos']=(df['rating']>8.0)\n",
    "df['neg']=(df['rating']<5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=4565)\n",
    "#Split into test/training.\n",
    "Ntot=len(df)\n",
    "Ntrain=int(0.9*Ntot)\n",
    "\n",
    "msk=np.random.random(Ntot)<0.9\n",
    "df_train=df.loc[msk]\n",
    "#note this \"test\" is different from Matt's \"realtest\" data.\n",
    "df_test=df.loc[~msk]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Since this is primarily for exploration, I'm going to limit the vectorizer to fairly common words (which occur in more than 50 messages).\n",
    "Increasing this threshold seems to pull out more meaningful estimates for the conditional probabilities for positive and negative words.\n",
    "\n",
    "It's also possible to not just use  the raw count vectorizer, but also the TF-IDF, which includes an additional weighting that de-emphasizes common words.  This apparently makes a term-frequency matrix whose spectrum better matches some of the assumptions for the SVD.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#borrowing from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "count_vect=CountVectorizer(stop_words='english',lowercase=True,strip_accents='unicode',ngram_range=(1,1),min_df=50)\n",
    "X_train_counts=count_vect.fit_transform(df_train['comment_clean'])\n",
    "X_test_counts=count_vect.transform(df_test['comment_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(count_vect,open('pickled/count_vect','wb'))\n",
    "pickle.dump(X_train_counts,open('pickled/X_train_counts','wb'))\n",
    "pickle.dump(X_test_counts,open('pickled/X_test_counts','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So one of the problems with going to multiple n-grams is the ease with which you start overfitting.  This can be combatted by\n",
    "playing with the min\\_df parameter.  \n",
    "Maybe I could explore adjusting this size manually, with the size of ngrams.\n",
    "\n",
    "Given the 2-grams it's probably also possible to do some analysis from the conditional probabilities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vect=TfidfVectorizer(stop_words='english',lowercase=True,strip_accents='unicode',min_df=50)\n",
    "X_train_tfidf=tfidf_vect.fit_transform(df_train['comment_clean'])\n",
    "X_test_tfidf=tfidf_vect.transform(df_test['comment_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(tfidf_vect,open('pickled/tfidf_vect','wb'))\n",
    "pickle.dump(X_train_tfidf,open('pickled/X_train_tfidf','wb'))\n",
    "pickle.dump(X_test_tfidf,open('pickled/X_test_tfidf','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#transform the real test set\n",
    "X_realtest_counts=count_vect.transform(df_real_test['comment_clean'])\n",
    "X_realtest_tfidf=tfidf_vect.transform(df_real_test['comment_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Checking the vectorizer and finding common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I wanted to check that the vectorizer was working by outputting common words, and identifying the \"most positive/negative\" words, based on their counts.  This was useful as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def find_indicator_words(counts,val,count_vect):\n",
    "    #Make a dataframe from the vectorizer vocabulary, and sort it so its entries correspond to the vectorizer indices.  \n",
    "    voc_dict=count_vect.vocabulary_\n",
    "    voc_df=pd.DataFrame.from_dict(voc_dict,orient='index')\n",
    "    voc_df1=voc_df.sort_values(by=0)\n",
    "    #Compute conditional probabilities of toxicity for each word. \n",
    "    p_pos,pw_pos,pw_neg = cond_prob( counts, val, csmooth=0.000001)\n",
    "    #make new dataframe with conditional probabilities for words being toxic, and raw probabilities of occuring in toxic/clean messages\n",
    "    #Then sort by toxicity.\n",
    "    X_cond= pw_pos*p_pos/(pw_pos*p_pos + pw_neg*(1-p_pos))\n",
    "    tf=counts.sum(axis=0)\n",
    "    df=(counts>0).sum(axis=0)\n",
    "    word_mat=np.array([tf,df,X_cond,pw_pos,pw_neg]).squeeze()\n",
    "    word_df=pd.DataFrame(word_mat.T,columns=['term-count','doc-count','pcond','p_hit','p_miss'],index=voc_df1.index)\n",
    "    word_df.sort_values('pcond',ascending=False,inplace=True)\n",
    "    print(word_df.head(n=20))\n",
    "    return word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              term-count  doc-count     pcond     p_hit    p_miss\n",
      "hilinski           101.0       93.0  0.779699  0.000024  0.000002\n",
      "perfection         383.0      375.0  0.748815  0.000086  0.000009\n",
      "x1                 207.0       77.0  0.694766  0.000043  0.000006\n",
      "shards              55.0       54.0  0.693681  0.000011  0.000002\n",
      "masterpiece       1382.0     1370.0  0.692217  0.000288  0.000040\n",
      "automa             102.0       85.0  0.690376  0.000021  0.000003\n",
      "keldons             75.0       72.0  0.677468  0.000015  0.000002\n",
      "masterful          126.0      126.0  0.666385  0.000025  0.000004\n",
      "salsa               82.0       71.0  0.654280  0.000016  0.000003\n",
      "afar                77.0       76.0  0.645688  0.000015  0.000003\n",
      "wonderfull         103.0       99.0  0.643496  0.000020  0.000003\n",
      "awesomeness        207.0      203.0  0.635299  0.000040  0.000007\n",
      "flawless           252.0      249.0  0.633890  0.000048  0.000009\n",
      "sublime            125.0      124.0  0.622876  0.000024  0.000004\n",
      "breathtaking        50.0       50.0  0.622876  0.000009  0.000002\n",
      "bravo              110.0      104.0  0.619170  0.000021  0.000004\n",
      "nr                  78.0       67.0  0.610861  0.000014  0.000003\n",
      "10s                205.0      203.0  0.602020  0.000037  0.000008\n",
      "magnum              55.0       51.0  0.600668  0.000010  0.000002\n",
      "todd               112.0      101.0  0.598523  0.000020  0.000004\n"
     ]
    }
   ],
   "source": [
    "posword_df=find_indicator_words(X_train_counts,df_train['pos'].values,count_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Well, this seems to have found some positive words, as well as some user names, and what I think are actually part of game names (\"salsa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              term-count  doc-count     pcond     p_hit    p_miss\n",
      "blech              102.0       99.0  0.657465  0.000064  0.000003\n",
      "spinner             98.0       92.0  0.654377  0.000061  0.000003\n",
      "yuck               134.0      133.0  0.644830  0.000083  0.000004\n",
      "redeeming          182.0      180.0  0.639864  0.000111  0.000005\n",
      "ugh                539.0      534.0  0.569131  0.000295  0.000018\n",
      "ladders            116.0      115.0  0.521801  0.000058  0.000004\n",
      "interminable        90.0       90.0  0.511985  0.000045  0.000003\n",
      "yawn               274.0      262.0  0.489557  0.000130  0.000011\n",
      "fanboys             55.0       54.0  0.487699  0.000026  0.000002\n",
      "torture            189.0      183.0  0.486545  0.000089  0.000007\n",
      "bleh               184.0      182.0  0.478618  0.000085  0.000007\n",
      "garbage            275.0      264.0  0.476803  0.000127  0.000011\n",
      "mercifully          73.0       72.0  0.471785  0.000033  0.000003\n",
      "loathe             211.0      206.0  0.471526  0.000096  0.000009\n",
      "snakes              80.0       76.0  0.466154  0.000036  0.000003\n",
      "oatmeal             70.0       69.0  0.450168  0.000031  0.000003\n",
      "numbingly           60.0       60.0  0.445440  0.000026  0.000003\n",
      "toilet              63.0       62.0  0.439142  0.000027  0.000003\n",
      "unengaging          50.0       50.0  0.438827  0.000021  0.000002\n",
      "hatred              74.0       70.0  0.424911  0.000031  0.000003\n"
     ]
    }
   ],
   "source": [
    "negword_df=find_indicator_words(X_train_counts,df_train['neg'].values,count_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So let's look at what this pulled out for \"negative words\".\n",
    "\n",
    "There are expressions of boredom: \"interminable, torture, numbingly\".\n",
    "Disgust: \"yuck, blech, garbage,ugh\"\n",
    "Dislike:\"torture, garbage, hatred, loathe\".\n",
    "\n",
    "And what I think is \"snakes and ladders\".\n",
    "\n",
    "Prior to eliminating duplicate comments, this also found user names associated with reviews spamming 1s.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def find_words(df,st):\n",
    "    msk=df['comment_clean'].str.contains(st)\n",
    "    print(df[msk].head())\n",
    "    print(df[msk].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# K-folds\n",
    "\n",
    "Let's split the training data into k-folds so we can do some cross-validation for tuning hyper-parameters.\n",
    "This will primarily show up on tuning the vectorization procedure, and any fitting hyper parameters (regularization).\n",
    "It can also be used to compare the input stages (convert scores to percentiles).\n",
    "This will be useful in tuning the inputs like vectorizer size, as well as any dimensionality reduction.\n",
    "For Naive Bayes, there aren't any parameters, but this will be useful for the neural networks, regression, and SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "skf=StratifiedKFold(n_splits=5,random_state=20483)\n",
    "#grab the first iteration here.\n",
    "train_index, dev_index=skf.split(df_train, df_train['pos']).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Note: really need to use iloc here.  \n",
    "df_train0=df_train.iloc[train_index]\n",
    "df_dev0=df_train.iloc[dev_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "I want to implement a Naive Bayes classifier as a baseline.  I've written my own version, which I will try to compare to\n",
    "scikit-learn's version.  (They both return the same result now).  Note that my version is written for only binary classification.\n",
    "\n",
    "This basically treats the comments in a bag-of-words sense, and drops any correlations between the words.  \n",
    "\n",
    "* Estimate $p(w|T)$ from counts in term-frequency matrix.\n",
    "* Use Bayes Rule\n",
    "  $ P(T|w) = \\frac{p(T)p(w|T)}{\\text{normalization const}}$\n",
    "\n",
    "  \\begin{equation}\n",
    "    p(T|\\text{words}) = P(T) \\prod_{words}\\frac{p(w_i|T)}{p(w_i|T)\n",
    "  \\end{equation}\n",
    "\n",
    "* Use Logarithms, and compare log-odds for positive/non-positive.\n",
    "\n",
    "So this is a classification point of view.  Ultimately, we want to treat this as a regression problem.\n",
    "A classification algorithm is a poor fit for this, since it ignores the similarity between adjacent scores. \n",
    "Nonetheless, I have a working version, so let's play with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#go though this split, and find the hits\n",
    "actual_pos=df_train0['pos'].values\n",
    "actual_pos_dev=df_dev0['pos'].values\n",
    "actual_neg=df_train0['neg'].values\n",
    "actual_neg_dev=df_dev0['neg'].values\n",
    "msk=actual_pos\n",
    "#find indices for both split and hit.\n",
    "train_hit_msk=train_index[msk]\n",
    "Xhit = X_train_counts[train_index]\n",
    "#compute conditional probabilities within this sample\n",
    "p_hit,pw_hit,pw_miss = cond_prob( Xhit, actual_pos, csmooth=0.000001)\n",
    "#now compute the bayes factors\n",
    "pred_pos,prob,logH,logM,log_Hword,log_Mword=naive_bayes(Xhit,pw_hit,pw_miss,p_hit)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb9308d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot a histogram of the log probabilities.  \n",
    "plt.figure()\n",
    "plt.hist(np.maximum(-10,np.log(prob)),bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb981d1d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot a histogram of the log-odds \n",
    "plt.figure()\n",
    "bins=np.linspace(-20,20,100)\n",
    "plt.hist(logH-logM,bins=bins,log=True)\n",
    "plt.ylabel('Counts')\n",
    "plt.xlabel('Log Odds of Hit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Maybe should also plot length of comments? To what extent are the tails mirroring a similar underlying shape, with long tails, and differing semantic content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "com_len=df_train['comment_clean'].apply(lambda x: len(str.split(x,' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb85e87160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(com_len,log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss is 7.357670564439999\n",
      "AUROC is 0.6654193378236977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595659, 1) (595659, 1)\n",
      "True Positive 0.10308918357650938. False Positive 0.07842742240107176\n",
      "False Negative 0.13459714366776965. True Negative 0.6838862503546492\n"
     ]
    }
   ],
   "source": [
    "logloss,score_rates=check_predictions(pred_pos,actual_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So let's just use the Scikit-learn version of this, making my own was amusing, but the scikit-learn version can handle multiple classes, and presumably runs faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#alpha is the smoothing parameter for counts.\n",
    "pos_nb = MultinomialNB(alpha=0.01)\n",
    "neg_nb= MultinomialNB(alpha=0.01)\n",
    "pos_nb.fit(X_train_counts[train_index],df_train0['pos'].values)\n",
    "neg_nb.fit(X_train_counts[train_index],df_train0['neg'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Make predictions on training/dev sets\n",
    "pred_pos_nb=pos_nb.predict(X_train_counts[train_index])\n",
    "pred_pos_dev_nb=pos_nb.predict(X_train_counts[dev_index])\n",
    "pred_neg_nb=neg_nb.predict(X_train_counts[train_index])\n",
    "pred_neg_dev_nb=neg_nb.predict(X_train_counts[dev_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss is 2.9266067895623347\n",
      "AUROC is 0.6664242912117463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss is 7.358192423065742\n",
      "AUROC is 0.6653899841156704\n",
      "(595659, 1) (595659, 1)\n",
      "True Positive 0.027455305804159762. False Positive 0.03895013757871534\n",
      "False Negative 0.04578290599151528. True Negative 0.8878116506256096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Training data\n",
      "(595659, 1) (595659, 1)\n",
      "True Positive 0.10307575307348668. False Positive 0.0784291012139496\n",
      "False Negative 0.13461057417079236. True Negative 0.6838845715417714\n"
     ]
    }
   ],
   "source": [
    "print('Checking Training data')\n",
    "nb_stats=check_predictions(pred_pos_nb,actual_pos)\n",
    "nb_stats=check_predictions(pred_neg_nb,actual_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC is 0.6466539733136522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dev set\n",
      "(148915, 1) (148915, 1)\n",
      "True Positive 0.09882819057851795. False Positive 0.08022697512003492\n",
      "False Negative 0.13885773763556392. True Negative 0.6820870966658832\n",
      "Log-loss is 7.566982054692003\n",
      "AUROC is 0.6552759119843594\n",
      "(148915, 1) (148915, 1)\n",
      "True Positive 0.025544773864284994. False Positive 0.0387670818923547\n",
      "False Negative 0.0506463418728805. True Negative 0.8850418023704798\n",
      "Log-loss is 3.088261248189909\n"
     ]
    }
   ],
   "source": [
    "print('Checking dev set')\n",
    "nb_stats=check_predictions(pred_pos_dev_nb,actual_pos_dev)\n",
    "nb_stats=check_predictions(pred_neg_dev_nb,actual_neg_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So we're evidently nowhere near overfitting.  There's similar performance across both training and dev sets.\n",
    "\n",
    "As it stands, this tends to miss on a large number of reviews, with both false-positives and false-negatives.\n",
    "\n",
    "For the \"negative reviews\", there are far fewer of those, perhaps reflecting the fact that popular games are by and large well received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Naive Bayes False Positives and Negatives\n",
    "\n",
    "Let's now look a bit at the misclassified results and see what we might be missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#fixing shapes to avoid broadcasting\n",
    "actual_pos=np.reshape(actual_pos,(len(actual_pos),1))\n",
    "pred_pos=np.reshape(pred_pos,(len(actual_pos),1))    \n",
    "\n",
    "fp_msk = ((pred_pos==True)&(actual_pos==False))\n",
    "\n",
    "fn_msk = ((pred_pos==False)&(actual_pos==True))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_fn=df_train0[fn_msk][['comment','rating']]\n",
    "df_fp=df_train0[fp_msk][['comment','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?neg_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                    comment  \\\n166417   I rated this one down from a 9 since it never hits the table.  The components are outstanding a...   \n166418  Thoughts based on just the first game, will change in future. Interesting command system, could-...   \n166425  Without the Broodwar expansion only a 7.  I always liked Starcraft, but i had several disappoint...   \n166426  Amazing and innovative game play, set in the StarCraft universe. A tough one to crack, but a joy...   \n166427                                Awesome.  See my review at http://www.boardgamegeek.com/thread/211664   \n166430  A fun, deep gameplay experience. Definitely Fantasy Flight as it took a while to learn those dar...   \n166432  PILE OF SHAME  Intimidating but seems brilliant. Haven't gotten it out for a proper game yet tho...   \n166433  English 1st edition Great condition (4 games)  House without pets or smoke.  The box includes th...   \n166435  The orders system creates some neat tension. I also love the different races and the difficult u...   \n166436  Awesome game, I simply _love_ the game mechanics! FFG has done a great job with making it feel l...   \n\n        rating  \n166417     8.0  \n166418     8.0  \n166425     8.0  \n166426     8.0  \n166427     8.0  \n166430     8.0  \n166432     8.0  \n166433     8.0  \n166435     8.0  \n166436     8.0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fp.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "At an initial scan, these seem to be very positive reviews, but for people who perhaps are fairly critical in how these use the scale.  (one conneisseurs 7, is another neophytes 10.)  Our criteria for positive is score>8.  And this is mischaracherizing 8.0 scores as being greater than 8.\n",
    "This hits at one of the difficulties here: predicting exactly how a user will use the rating system is hard, an expecting sub-0.5 resolution is perhaps a bit much  \n",
    "\n",
    "So this suggests that perhaps we need to scale a game and user's scores in order to get a decent estimate at an \"objective\" numerical rating.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                    comment  \\\n167535      Shiny. Must misbehave more often.  So much Browncoat fun in one small box. Great solitaire too.   \n167540                                            Fun, fun, fuuuuuuun! You can't take this game from me...    \n167546                                                                                                Next    \n167548  Fun game, not essential to have seen the TV series, but will add some additional enjoyment as yo...   \n167549  Understand why people would not like the game. I don't know if I would say it's a \"great\" game, ...   \n167553  This game is extremely faithful to the concept show and a whole lot of fun.  As I think others h...   \n167554  I love this game and the gameplay has a true to the show feel.  The only downside is time betwee...   \n167555  Game plays a little long.  Made some house rules to speed it up a bit.  Plays well as a Firefly ...   \n167575                                                                 always a fun quick game with friends   \n167577  Outstanding monster romp. Yahtzee, push your luck and resource/points collection I love to play ...   \n\n        rating  \n167535   10.00  \n167540    9.80  \n167546    9.50  \n167548    9.50  \n167549    9.50  \n167553    9.50  \n167554    9.30  \n167555    9.25  \n167575    9.00  \n167577    9.00  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fn.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Hmm, nothing obviously negative about this.  Perhaps not as effusive?  Really need to look at the scores on this.\n",
    "It seems like this subset of printed reviews is for the Firefly game, where fans are trying to offset negative scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Naive Bayes to Predict Score\n",
    "\n",
    "For fun, let's try putting each review into a bucket based on the score, and build a Naive Bayes classifier for each bin.\n",
    "This is a very simple way to try doing the regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Assign each half-integer bucket to an integer label.  e.g. .0-.5 is bucket 0, 0.5-1 -> 1, 1.0-1.5 ->3\n",
    "#Treat those as independent classes \n",
    "Ytrain=np.floor(df_train['rating']*2).values.astype(int)\n",
    "Ytrain0=Ytrain[train_index]\n",
    "Ydev0=Ytrain[dev_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_all = MultinomialNB(alpha=0.01)\n",
    "nb_all.fit(X_train_counts[train_index],Ytrain0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pred_nb_all=nb_all.predict(X_train_counts[train_index])/2\n",
    "pred_dev_nb_all=nb_all.predict(X_train_counts[dev_index])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def errors(x,y):\n",
    "    rmse=np.sqrt(np.mean( (x-y)*(x-y)))\n",
    "    mad=np.mean(np.abs(x-y))\n",
    "    return {'RMSE':rmse,'MAD':mad}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAD': 1.0885627274497354, 'RMSE': 1.5811913489883482}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(pred_nb_all,df_train0['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28499023770311538"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred_nb_all==df_train0['rating'].values)/len(df_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAD': 1.2970124246420365, 'RMSE': 1.6933319051527553}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(7.2,df_train0['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's check this against the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAD': 1.1618099698485775, 'RMSE': 1.6334742919950866}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(pred_dev_nb_all,df_dev0['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAD': 1.307295365947063, 'RMSE': 1.7027968731059731}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(7.2,df_dev0['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So, it does a bit better than the super simple guess.\n",
    "One of the downsides of this particular problem is that the scores are fairly similar.\n",
    "These are by and large, good games, so they have good scores. \n",
    "People also use the rating scale inconsistently, so there is quite a bit of noise in the mapping from sentiment to score.  I think this is the largest issue with this dataset. \n",
    "\n",
    "I think this (like the previous rating experiment) will struggle to push below this noise floor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#now predict all counts\n",
    "pred_realtest_nb=nb_all.predict(X_realtest_counts)/2\n",
    "df_real_test['nb']=pred_realtest_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?X_train_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_real_test['const']=7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_real_test[['userID','gameID','nb']].to_csv('data/nb_test_pred.csv',index=False)\n",
    "df_real_test[['userID','gameID','const']].to_csv('data/const_test_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Regularized Linear Regression\n",
    "\n",
    "We could just face the fact this is a regression problem, and build a linear regressor on the term-frequency matrix.\n",
    "This basically fits a model of the form:\n",
    "\\begin{equation}\n",
    "  y^{(i)} = \\sum_j w_j f_j^{(i)}\n",
    "\\end{equation}\n",
    "where $f_j^{(i)}$ is the count for token $j$ in comment $i$.  The weights $w_i$ are what we are fitting for, with a cost function\n",
    "\\begin{equation}\n",
    "    J = N^{-1}\\sum_i ( \\hat{y}^{(i)}-y^{(i)})^2.\n",
    "\\end{equation}\n",
    "I'll try to use a couple regularizations here: ridge and lasso regression which add penalities $\\alpha_2\\sum_iw_i^2$  and $\\alpha_1\\sum_i |w_i|$ respectively. It looks like the parameters are quite sensitive.\n",
    "\n",
    "Of the two, the lasso tends to return a sparse model, in that most of the coefficients $w_j$ will be zero, since the regularization is stronger closer to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Y=df_train['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-06,   3.16227766e-04,   1.00000000e-01])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-6,-1,num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "parameters={'alpha':np.logspace(-6,2,num=8)}\n",
    "ridge=linear_model.Ridge()\n",
    "lasso=linear_model.Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=None, solver='auto', tol=0.001),\n       fit_params=None, iid=True, n_jobs=2,\n       param_grid={'alpha': array([  1.00000e-06,   1.38950e-05,   1.93070e-04,   2.68270e-03,\n         3.72759e-02,   5.17947e-01,   7.19686e+00,   1.00000e+02])},\n       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do automated grid-search via k-fold cross validation\n",
    "ridge_cv=GridSearchCV(ridge,parameters,n_jobs=2)\n",
    "ridge_cv.fit(X_train_counts[:100000], Y[:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 100.0}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#takes a while with the full matrix.   \n",
    "ridgecv_pred2=ridge_cv.predict(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ridgecv_pred_realtest=ridge_cv.predict(X_realtest_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAD': 1.1067650147227397, 'RMSE': 1.4621549029290382}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors(ridgecv_pred2,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_real_test['Rpred_cv']=ridgecv_pred_realtest\n",
    "df_real_test[['userID','gameID','Rpred_cv']].to_csv('predictions/ridgecv_test_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Lasso Regression\n",
    "\n",
    "This is just a quick attempt to fit a lasso regression.\n",
    "This just uses a slightly hand tuned guess. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes a while with the full matrix.   \n",
    "lasso.fit(X_train_counts[train_index], Y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Rpred=ridge.predict(X_train_counts[train_index])\n",
    "Rpred_dev=ridge.predict(X_train_counts[dev_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Lpred=lasso.predict(X_train_counts[train_index])\n",
    "Lpred_dev=lasso.predict(X_train_counts[dev_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Now run it on the test data. \n",
    "Lpred_real_test=lasso.predict(X_realtest_counts)\n",
    "df_real_test['Lpred']=Lpred_real_test\n",
    "df_real_test[['userID','gameID','Lpred']].to_csv('data/lasso_test_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso train error: {'RMSE': 1.5964427269415096, 'MAD': 1.2083386291499489}\n",
      "Lasso dev error: {'RMSE': 1.6041091242369758, 'MAD': 1.2177823248817377}\n"
     ]
    }
   ],
   "source": [
    "print('Lasso train error:',errors(Lpred,Y[train_index]))\n",
    "print('Lasso dev error:',errors(Lpred_dev,Y[dev_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge train error: {'RMSE': 1.4167511640051815, 'MAD': 1.0732287882234155}\n",
      "Ridge dev error: {'RMSE': 1.4550694344298802, 'MAD': 1.1025028099380467}\n"
     ]
    }
   ],
   "source": [
    "print('Ridge train error:',errors(Rpred,Y[train_index]))\n",
    "print('Ridge dev error:',errors(Rpred_dev,Y[dev_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595659, 595659)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_nb_all),len(Y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb6c2aae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Error Distribution\n",
    "bins=np.linspace(-10,10,41)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.title('Raw Distributions')\n",
    "plt.subplot(131)\n",
    "plt.hist(Lpred-Y[train_index],bins=bins,log=True)\n",
    "plt.title('Lasso Regression')\n",
    "plt.subplot(132)\n",
    "plt.hist(Rpred-Y[train_index],bins=bins,log=True)\n",
    "plt.title('Ridge Regression')\n",
    "plt.subplot(133)\n",
    "plt.hist(pred_nb_all-Y[train_index],bins=bins,log=True)\n",
    "plt.title('Naive Bayes Multiclassification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb4af654a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Raw Distributions\n",
    "bins=np.linspace(0,10,21)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.title('Raw Distributions')\n",
    "plt.subplot(141)\n",
    "plt.hist(Lpred,bins=bins,log=True)\n",
    "plt.title('Lasso Regression')\n",
    "plt.subplot(142)\n",
    "plt.hist(Rpred,bins=bins,log=True)\n",
    "plt.title('Ridge Regression')\n",
    "plt.subplot(143)\n",
    "plt.hist(pred_nb_all,bins=bins,log=True)\n",
    "plt.title('Naive Bayes Multiclassification')\n",
    "plt.subplot(144)\n",
    "plt.hist(df['rating'],bins=bins,log=True)\n",
    "plt.title('Actual Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41936764436977703, 0.92026854310893547)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lpred.std(), Rpred.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Hmm, evidently, the lasso wil require tuning those parameters quite a bit.  It takes a few minutes to fit a model (large number of dimensions).\n",
    "Perhaps doing some dimensionality reduction will help. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "Let's use the truncated SVD for dimensionality reduction.\n",
    "Apparently TF-IDF matrix is superior to straight term frequency matrix for this purpose  (more closely matches assumptions in the SVD about the noise.)\n",
    "This should use a sparse algorithm (and preserve that sparsity) in the resulting matrices. \n",
    "\n",
    "I should may also symmetrize transformation (as suggested in paper comparing hyperparameters between word2vec and older SVD methods) for word embeddings. They suggest using $T=U \\Lambda V = (U \\Lambda^{1/2}) (\\Lambda^{1/2} V)$ for the projection.\n",
    "So if we have a term-frequency matrix, $M$, the transformed matrix should be given by $M'=M(U \\Lambda^{1/2})$, rather than $M''=MU$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=200, n_iter=20,\n       random_state=2847, tol=0.0)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "#took around 5 min on laptop.\n",
    "TSVD=TruncatedSVD(n_components=200,n_iter=20,random_state=2847)\n",
    "TSVD.fit(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#actually transform the results \n",
    "X_train_trans=TSVD.transform(X_train_tfidf)\n",
    "X_test_trans=TSVD.transform(X_test_tfidf)\n",
    "X_realtest_trans=TSVD.transform(X_realtest_tfidf)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(TSVD,open('pickled/TSVD','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba7f57400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbbb5c85f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(121)\n",
    "plt.loglog(TSVD.explained_variance_)\n",
    "plt.xlabel('Singular value label')\n",
    "plt.ylabel('Singular value')\n",
    "plt.subplot(122)\n",
    "plt.plot(TSVD.explained_variance_)\n",
    "plt.xlabel('Singular value label')\n",
    "plt.ylabel('Singular value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb8a8dee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(TSVD.explained_variance_ratio_)\n",
    "plt.plot(np.cumsum(TSVD.explained_variance_ratio_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So looks like power-law decay in the spectrum. We're primarily interested in using this\n",
    "for dimensionality reduction.  Ideally, I'd pick some reasonable threshold for keeping a\n",
    "certain fraction of the explained variance.\n",
    "(Could estimate a power law tail, compute threshold to capture that percentage).\n",
    "\n",
    "But for now, we'll just set the threshold to be 100, as a suitably small arbitrary choice.  \n",
    "We will next use the transformed results in a feedforward neural network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#actually transform the dev/test data.\n",
    "X_test_trans=TSVD.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Deep Network\n",
    "\n",
    "Another idea is to build a deep neural network on the term-frequency matrix, effectively running with extensions to the Naive Bayes model.\n",
    "This is a nonlinear generalization of the naive Bayes/regression approaches based on how we choose to do this.\n",
    "\n",
    "We could train the model to predict the scores as classification (as in the Bayesian approach), or we could get the network to spit out a number, \n",
    "\n",
    "This will use the reduced term-frequency matrix after the Truncated SVD.\n",
    "\n",
    "Another approach to vectorizing is to use pre-trained wordvectors for each token.  Then just use the average for the whole comment.\n",
    "A more complex model could preserve the temporal order of this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected, l2_regularizer\n",
    "from tensorflow.contrib.rnn import BasicRNNCell,LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from deep_network import deep_dropout_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Ignore the \"error about serializing - this is a known problem with saving models created using \n",
    "#modules like fully connected, since their components are not named.\n",
    "#The models are saved, and the computations work.\n",
    "\n",
    "X=X_train_trans[train_index]\n",
    "# just try predicting output score scaled from [0-1]\n",
    "Y0=Y[train_index]/10\n",
    "save_name='./tf_models/deep_relu_drop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "dNN=deep_dropout_NN(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#actually train the model - this is slow. \n",
    "dNN.run_graph(X,Y0,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newer predict\n",
      "INFO:tensorflow:Restoring parameters from ./tf_models/deep_relu_drop-10000\n"
     ]
    }
   ],
   "source": [
    "#model_name='tf_models/deep_relu_drop-{}'.format(dNN.n_iter)\n",
    "dNN.keep_prob=1\n",
    "model_name='./tf_models/deep_relu_drop-{}'.format(10000)\n",
    "dnn_pred2=dNN.predict_all(model_name,X_train_trans)\n",
    "dnn_pred2=dnn_pred2.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#find values larger than 10\n",
    "msk=dnn_pred2>1\n",
    "dnn_pred2[msk]=1\n",
    "msk=dnn_pred2<0\n",
    "dnn_pred2[msk]=0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train {'RMSE': 1.5597578664428968, 'MAD': 1.1769857055904218}\n"
     ]
    }
   ],
   "source": [
    "#Check scores on training data\n",
    "print('Train',errors(dnn_pred2[train_index]*10,Y[train_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev {'RMSE': 1.5749093350166528, 'MAD': 1.1890763885231692}\n"
     ]
    }
   ],
   "source": [
    "print('Dev',errors(dnn_pred2[dev_index]*10,Y[dev_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Const {'RMSE': 1.6952291289531762, 'MAD': 1.2990690156648506}\n"
     ]
    }
   ],
   "source": [
    "print('Const',errors(7.2,df_train['rating']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's look at those errors now, and compare the results for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb43ab49e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins=np.linspace(-10,10,41)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.title('Raw Distributions')\n",
    "# plt.subplot(141)\n",
    "# plt.hist(Lpred-Y[train_index],bins=bins,log=True)\n",
    "# plt.title('Lasso Regression')\n",
    "plt.subplot(142)\n",
    "plt.hist(ridgecv_pred2[train_index]-Y[train_index],bins=bins,log=True)\n",
    "plt.title('Ridge Regression')\n",
    "plt.subplot(143)\n",
    "plt.hist(pred_nb_all-Y[train_index],bins=bins,log=True)\n",
    "plt.title('Naive Bayes Multiclassification')\n",
    "plt.subplot(144)\n",
    "plt.hist(dnn_pred2[train_index]*10-Y[train_index],bins=bins,log=True)\n",
    "plt.title('Neural Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newer predict\n",
      "INFO:tensorflow:Restoring parameters from ./tf_models/deep_relu_drop-10000\n"
     ]
    }
   ],
   "source": [
    "dnn_realtest_pred=dNN.predict_all(model_name,X_realtest_trans)*10\n",
    "dnn_realtest_pred=dnn_realtest_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_real_test['DNN']=dnn_realtest_pred\n",
    "df_real_test[['userID','gameID','DNN']].to_csv('predictions/DNN_test_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Some interesting differences in terms of the shapes of the output distributions based on method.\n",
    "\n",
    "Right now the network doesn't know about the scoring.  Some fiddling to round the scores and truncate them could be done.  \n",
    "But, I think ultimately the oddities in how the data is scored (clustered around 7, with variability in terms of who is scoring is the problem).\n",
    "\n",
    "So ways to fix that:\n",
    "- Normalize the scores.\n",
    "- Instead predict score quantiles so we're targetting a flat distribution?  \n",
    "- Include categorical variables for user/game?\n",
    "- Perhaps some variety of boosting?  Look at mis-classified results, develop tweak/model to characterize those? Perhaps normalize/scale the scores by user and by game? \n",
    "\n",
    "Well, we still haven't really tried tuning these models yet.  These are just parameters picked from giving decent results, rather than optimal ones.\n",
    "\n",
    "In addition, all of these methods are just trying to work on the word-count matrices.  This throws away the semantics and just looks for a few indicator words.  An extension\n",
    "\n",
    "Let's think about the use-case here. Why would I care about getting the score exactly right? Wouldn't I care more about guessing positive/negative based on the text.  What am I aiming for here?  A better recommender tool?  In that case maybe some named entity recognition would be needed?\n",
    "So if I say \"For fans of Settlers of Catan\", or SOC it picks that up?\n",
    "This usecase comes from reading copious amounts of reviews, where a band is mentioned in passing, as having a similar sound.\n",
    "It would be nice to have an automated tool to make those recommendations. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "So let's try the current flavour of the month approach: a recurrent neural network.\n",
    "Let's try something similar, with initially a single layer leaky ReLU layer.\n",
    "\n",
    "The idea is that the network parses each word of the sentence (to better capture logical structure).\n",
    "Each word needs an index.  Initially this is an index in the vocabulary V, where $V\\sim10^6$ or more.  That's an infeasibly large matrix.\n",
    "We need some form of dimensionality reduction.  Either by picking the most distinctive words (which actually appear in multiple messages),\n",
    "or by projecting down via SVD.\n",
    "\n",
    "I think making this efficient requires loading the word embedding matrix onto the GPU\n",
    "- use the embedding lookup function\n",
    "- use a batch generator.\n",
    "- add an estimator interface to allow sklearn to optimize hyperparameters.\n",
    "- add variable for length of comment.\n",
    "- look up inluded EOS markers?\n",
    "- hierarchical neural network?  RNN sentences to vec, RNN sentence vec to doc, doc2vec?\n",
    "- \n",
    "- make a pipeline (comment-to-vec, regression)\n",
    "- make a new sklearn metric for weighted least squares.\n",
    "- make estimator interface\n",
    "- do \n",
    "- tune hyperparameters (layers, size, stop-words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from util import load_glove, sentence_lookup, sent_to_matrix\n",
    "\n",
    "glove_vec,glove_dict=load_glove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train['comment_vec_index']=df_train['comment_clean'].apply(lambda x:sentence_lookup(x,glove_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mat=sent_to_matrix(df_train.loc[20,'comment_vec_index'],glove_vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "init_explore.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
